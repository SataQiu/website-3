"use strict";(self.webpackChunkkoordinator_sh=self.webpackChunkkoordinator_sh||[]).push([[1477],{10:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"release-v0.4.0","metadata":{"permalink":"/blog/release-v0.4.0","editUrl":"https://github.com/koordinator-sh/koordinator.sh/edit/main/blog/2022-05-31-release/index.md","source":"@site/blog/2022-05-31-release/index.md","title":"What\'s New in Koordinator v0.4.0?","description":"We are happy to announce the release of Koordinator v0.4.0. Koordinator v0.4.0 brings in some notable changes that are most wanted by the community while continuing to expand on experimental features. And in this version, we started to gradually enhance the capabilities of the scheduler.","date":"2022-05-31T00:00:00.000Z","formattedDate":"May 31, 2022","tags":[{"label":"release","permalink":"/blog/tags/release"}],"readingTime":7.39,"truncated":false,"authors":[{"name":"Joseph","title":"Koordinator maintainer","url":"https://github.com/eahydra","imageURL":"https://github.com/eahydra.png","key":"joseph"}],"frontMatter":{"slug":"release-v0.4.0","title":"What\'s New in Koordinator v0.4.0?","authors":["joseph"],"tags":["release"]},"nextItem":{"title":"What\'s New in Koordinator v0.3.0?","permalink":"/blog/release-v0.3.0"}},"content":"We are happy to announce the release of Koordinator v0.4.0. Koordinator v0.4.0 brings in some notable changes that are most wanted by the community while continuing to expand on experimental features. And in this version, we started to gradually enhance the capabilities of the scheduler.\\n\\n## Install or Upgrade to Koordinator v0.4.0\\n\\n### Install with helms\\n\\nKoordinator can be simply installed by helm v3.5+, which is a simple command-line tool, and you can get it\\nfrom [here](https://github.com/helm/helm/releases).\\n\\n```shell\\n# Firstly add koordinator charts repository if you haven\'t do this.\\n$ helm repo add koordinator-sh https://koordinator-sh.github.io/charts/\\n\\n# [Optional]\\n$ helm repo update\\n\\n# Install the latest version.\\n$ helm install koordinator koordinator-sh/koordinator --version 0.4.0\\n```\\n\\n### Upgrade with helm\\n\\n```shell\\n# Firstly add koordinator charts repository if you haven\'t do this.\\n$ helm repo add koordinator-sh https://koordinator-sh.github.io/charts/\\n\\n# [Optional]\\n$ helm repo update\\n\\n# Upgrade the latest version.\\n$ helm upgrade koordinator koordinator-sh/koordinator --version 0.4.0 [--force]\\n```\\n\\nFor more details, please refer to the [installation manual](/docs/installation).\\n\\n## Enhanced node-side scheduling capabilities\\n\\n### Custom memory evict threshold\\n\\nIn the Koordinator v0.2.0, an ability to improve the stability of the node side in the co-location scenario was introduced: [Active eviction mechanism based on memory safety thresholds](/blog/release-v0.2.0#active-eviction-mechanism-based-on-memory-safety-thresholds). The current memory utilization safety threshold default value is 70%, now in the v0.4.0 version, you can modify the `memoryEvictThresholdPercent` with 60% in ConfigMap `slo-controller-config` according to the actual situation:\\n\\n```yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: slo-controller-config\\n  namespace: koordinator-system\\ndata:\\n  colocation-config: |\\n    {\\n      \\"enable\\": true\\n    }\\n  resource-threshold-config: |\\n    {\\n      \\"clusterStrategy\\": {\\n        \\"enable\\": true,\\n        \\"memoryEvictThresholdPercent\\": 60\\n      }\\n    }\\n```\\n\\n### BE Pods eviction based on satisfaction\\n\\nIn order to ensure the runtime quality of different workloads in co-located scenarios, Koordinator uses the CPU Suppress mechanism provided by koordlet on the node side to suppress workloads of the best effort type when the load increases. Or increase the resource quota for best effort type workloads when the load decreases. \\n\\nHowever, it is not suitable if there are many best effort Pods on the node and they are frequently suppressed. Therefore, in version v0.4.0, Koordinator provides an eviction mechanism based on satisfaction of the requests for the best effort Pods. If the best effort Pods are frequently suppressed, the requests of the best effort Pods cannot be satisfied, and the satisfaction is generally less than 1; if the best effort Pods are not suppressed and more CPU resources are obtained when the node resources are idle, then the requests of the best effort Pods can be satisfied, and the satisfaction is greater than or equal to 1. If the satisfaction is less than the specified threshold, and the CPU utilization of the best effort Pods is close to 100%, `koordlet` will evict some best effort Pods to improve the runtime quality of the node. The priority with lower priority or with higher CPU utilization of the same priority is evicted.\\n\\nYou can modify the ConfigMap `slo-controller-config` according to the actual situation:\\n\\n```yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: slo-controller-config\\n  namespace: koordinator-system\\ndata:\\n  colocation-config: |\\n    {\\n      \\"enable\\": true\\n    }\\n  resource-threshold-config: |\\n    {\\n      \\"clusterStrategy\\": {\\n        \\"enable\\": true,\\n        \\"cpuEvictBESatisfactionUpperPercent\\": 80,\\n        \\"cpuEvictBESatisfactionLowerPercent\\": 60\\n      }\\n    }\\n```\\n\\n### Group identity\\n\\nWhen latency-sensitive applications and best effort workloads are deployed on the same node, the Linux kernel scheduler must provide more scheduling opportunities to high-priority applications to minimize scheduling latency and the impacts of low-priority workloads on kernel scheduling. For this scenario, Koordinator integrated with the group identity allowing users to configure scheduling priorities to CPU cgroups. \\n\\nAlibaba Cloud Linux 2 with a kernel of the kernel-4.19.91-24.al7 version or later supports the group identity feature. The group identity feature relies on a dual red-black tree architecture. A low-priority red-black tree is added based on the red-black tree of the Completely Fair Scheduler (CFS) scheduling queue to store low-priority workloads. When the kernel schedules the workloads that have identities, the kernel processes the workloads based on their priorities. For more details, please refer to the [doc](https://www.alibabacloud.com/help/en/elastic-compute-service/latest/group-identity-feature).\\n\\nKoordinator defines group identity default values for Pods of different QoS types:\\n\\n| QoS | Default Value |\\n|-----|---------------|\\n| LSR | 2 |\\n| LS | 2 | \\n| BE | -1 |\\n\\nYou can modify the ConfigMap `slo-controller-config` to set group identity values according to the actual situation:\\n\\n```yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: slo-controller-config\\n  namespace: koordinator-system\\ndata:\\n  colocation-config: |\\n    {\\n      \\"enable\\": true\\n    }\\n  resource-qos-config: |\\n    {\\n      \\"clusterStrategy\\": {\\n        \\"lsr\\": {\\n            \\"cpuQoS\\": {\\n                \\"enable\\": \\"true\\",\\n                \\"groupIdentity\\": 2\\n            }\\n        },\\n        \\"ls\\": {\\n            \\"cpuQoS\\": {\\n                \\"enable\\": \\"true\\",\\n                \\"groupIdentity\\": 2\\n            }\\n        },\\n        \\"be\\": {\\n            \\"cpuQoS\\": {\\n                \\"enable\\": \\"true\\",\\n                \\"groupIdentity\\": -1\\n            }\\n        },\\n        \\"system\\": {\\n            \\"cpuQoS\\": {\\n                \\"enable\\": \\"true\\",\\n                \\"groupIdentity\\": 2\\n            }\\n        }\\n      }\\n    }\\n```\\n\\nIn addition, in order to enable this feature, in addition to updating the configuration file and updating the kernel, you also need to install the new component `koord-runtime-proxy` of koordinator.\\n\\n## KoordRuntimeProxy\\n\\nKoordRuntimeProxy acts as a proxy between kubelet and containerd(dockerd under dockershim scenario), which is designed to intercept CRI request, and apply some resource management policies, such as setting different cgroup parameters by pod priorities under hybrid workload orchestration scenario, applying new isolation policies for latest Linux kernel, CPU architecture, and etc.\\n\\nThere are two components involved, KoordRuntimeProxy and RuntimePlugins.\\n\\n![image](../../static/img/koord-runtime-proxy-architecture.svg)\\n\\n### KoordRuntimeProxy\\nKoordRuntimeProxy is in charge of intercepting request during pod\'s lifecycle, such as RunPodSandbox, CreateContainer etc., and then calling RuntimePlugins to do resource isolation policies before transferring request to backend containerd(dockerd) and after transferring response to kubelet. KoordRuntimeProxy provides an isolation-policy-execution framework which allows customized plugins registered to do specified isolation policies, these plugins are called RuntimePlugins. KoordRuntimeProxy itself does NOT do any isolation policies.\\n\\n### RuntimePlugins\\nRuntimePlugins register events(RunPodSandbox etc.) to KoordRuntimeProxy and would receive notifications when events happen. RuntimePlugins should complete resource isolation policies basing on the notification message, and then response KoordRuntimeProxy, KoordRuntimeProxy would decide to transfer request to backend containerd or discard request according to plugins\' response.\\n\\nIf no RuntimePlugins registered, KoordRuntimeProxy would become a transparent proxy between kubelet and containerd.\\n\\nFor more details, please refer to the [design doc](https://github.com/koordinator-sh/koordinator/blob/main/docs/design-archive/runtime-manager-design-doc.md).\\n\\n### Installation\\n\\nWhen installing KoordRuntimeProxy, you need to change the startup parameters of the kubelet, set the CRI parameters to point to the KoordRuntimeProxy, and configure the CRI parameters of the corresponding container runtime when installing the KoordRuntimeProxy. \\n\\nFor detailed installation process, please refer to the [documentation](https://github.com/koordinator-sh/koordinator/blob/main/docs/design-archive/koord-runtime-proxy-design-doc.md#installation).\\n\\n## Load-Aware Scheduling\\n\\nAlthough Koordinator provides the co-location mechanism to improve the resource utilization of the cluster and reduce costs, it does not yet have the ability to control the utilization level of the cluster dimension, Best Effort workloads may also interfere with latency-sensitive applications. Load-aware scheduling plugin helps Koordinator to achieve this capability.\\n\\nThe scheduling plugin filters abnormal nodes and scores them according to resource usage. This scheduling plugin extends the Filter/Score/Reserve/Unreserve extension points defined in the Kubernetes scheduling framework.\\n\\nBy default, abnormal nodes are filtered, and users can decide whether to enable or not by configuring as needed.\\n- Filter nodes where koordlet fails to update NodeMetric. \\n- Filter nodes by utilization thresholds. If the configuration enables, the plugin will exclude nodes with *latestUsageUtilization >= utilizationThreshold*.\\n\\nThis plugin is dependent on NodeMetric\'s reporting period. Different reporting periods need to be set according to different scenarios and workloads. Therefore, NodeMetricSpec has been extended to support user-defined reporting period and aggregation period. Users can modify `slo-controller-config` to complete the corresponding configuration, and the controller in `koord-manager` will be responsible for updating the reporting period and aggregation period fields of NodeMetrics of related nodes.\\n\\nCurrently, the resource utilization thresholds of nodes are configured based on experience to ensure the runtime quality of nodes. But there are also ways to evaluate the workload running on the node to arrive at a more appropriate threshold for resource utilization. For example, in a time-sharing scenario, a higher threshold can be set to allow scheduling to run more best effort workloads during the valley of latency-sensitive applications. When the peak of latency-sensitive applications comes up, lower the threshold and evict some best effort workloads. In addition, 3-sigma can be used to analyze the utilization level in the cluster to obtain a more appropriate threshold.\\n\\nThe core logic of the scoring algorithm is to select the node with the smallest resource usage. However, considering the delay of resource usage reporting and the delay of Pod startup time, the resource requests of the Pods that have been scheduled and the Pods currently being scheduled within the time window will also be estimated, and the estimated values will be involved in the calculation.\\n\\nAt present, Koordinator does not have the ability to profile workloads. Different types of workloads have different ways of building profiles. For example, long-running pods need to be scheduled with long-period profiling, while short-period pods should be scheduled with short-period profiling.\\n\\nFor more details, please refer to the [proposal](https://github.com/koordinator-sh/koordinator/blob/main/docs/proposals/scheduling/20220510-load-aware-scheduling.md).\\n\\n## What Comes Next\\n\\nFor more details, please refer to our [milestone](https://github.com/koordinator-sh/koordinator/milestones). Hope it\\nhelps!"},{"id":"release-v0.3.0","metadata":{"permalink":"/blog/release-v0.3.0","editUrl":"https://github.com/koordinator-sh/koordinator.sh/edit/main/blog/2022-05-07-release/index.md","source":"@site/blog/2022-05-07-release/index.md","title":"What\'s New in Koordinator v0.3.0?","description":"We are happy to announce the v0.3.0 release of Koordinator. After starting small and learning what users needed, we","date":"2022-05-07T00:00:00.000Z","formattedDate":"May 7, 2022","tags":[{"label":"koordinator","permalink":"/blog/tags/koordinator"},{"label":"colocation","permalink":"/blog/tags/colocation"},{"label":"kubernetes","permalink":"/blog/tags/kubernetes"},{"label":"scheduling","permalink":"/blog/tags/scheduling"},{"label":"orchestration","permalink":"/blog/tags/orchestration"},{"label":"release","permalink":"/blog/tags/release"}],"readingTime":10.92,"truncated":false,"authors":[{"name":"Jason","title":"Koordinator maintainer","url":"https://github.com/jasonliu747","imageURL":"https://github.com/jasonliu747.png","key":"jason"}],"frontMatter":{"slug":"release-v0.3.0","title":"What\'s New in Koordinator v0.3.0?","authors":["jason"],"tags":["koordinator","colocation","kubernetes","scheduling","orchestration","release"]},"prevItem":{"title":"What\'s New in Koordinator v0.4.0?","permalink":"/blog/release-v0.4.0"},"nextItem":{"title":"Koordinator v0.2.0 - Enhanced node-side scheduling capabilities","permalink":"/blog/release-v0.2.0"}},"content":"We are happy to announce the v0.3.0 release of **Koordinator**. After starting small and learning what users needed, we\\nare able to adjust its path and develop features needed for a stable community release.\\n\\nThe release of Koordinator v0.3.0 brings in some notable changes that are most wanted by the community while continuing\\nto expand on experimental features.\\n\\n## Install or Upgrade to Koordinator v0.3.0\\n\\n### Install with helms\\n\\nKoordinator can be simply installed by helm v3.5+, which is a simple command-line tool, and you can get it\\nfrom [here](https://github.com/helm/helm/releases).\\n\\n```shell\\n# Firstly add koordinator charts repository if you haven\'t do this.\\n$ helm repo add koordinator-sh https://koordinator-sh.github.io/charts/\\n\\n# [Optional]\\n$ helm repo update\\n\\n# Install the latest version.\\n$ helm install koordinator koordinator-sh/koordinator --version 0.3.0\\n```\\n\\n### Upgrade with helm\\n\\n```shell\\n# Firstly add koordinator charts repository if you haven\'t do this.\\n$ helm repo add koordinator-sh https://koordinator-sh.github.io/charts/\\n\\n# [Optional]\\n$ helm repo update\\n\\n# Upgrade the latest version.\\n$ helm upgrade koordinator koordinator-sh/koordinator --version 0.3.0 [--force]\\n```\\n\\nFor more details, please refer to the [installation manual](/docs/installation).\\n\\n## CPU Burst\\n\\nCPU Burst is a service level objective (SLO)-aware resource scheduling feature provided by Koordinator. You can use CPU\\nBurst to improve the performance of latency-sensitive applications. CPU scheduling for\\na container may be throttled by the kernel due to the CPU limit, which downgrades the performance of the application.\\nKoordlet automatically detects CPU throttling events and automatically adjusts the CPU limit to a\\nproper value. This greatly improves the performance of latency-sensitive applications.\\n\\n### How CPU Burst works\\n\\nKubernetes allows you to specify CPU limits, which can be reused based on time-sharing. If you specify a CPU limit for a\\ncontainer, the OS limits the amount of CPU resources that can be used by the container within a specific time period.\\nFor example, you set the CPU limit of a container to 2. The OS kernel limits the CPU time slices that the container can\\nuse to 200 milliseconds within each 100-millisecond period.\\n\\nCPU utilization is a key metric that is used to evaluate the performance of a container. In most cases, the CPU limit is\\nspecified based on CPU utilization. CPU utilization on a per-millisecond basis shows more spikes than on a per-second\\nbasis. If the CPU utilization of a container reaches the limit within a 100-millisecond period, CPU throttling is\\nenforced by the OS kernel and threads in the container are suspended for the rest of the time period.\\n\\n### How to use CPU Burst\\n\\n- Use an annotation to enable CPU Burst\\n\\n  Add the following annotation to the pod configuration to enable CPU Burst:\\n\\n```yaml\\nannotations:\\n  # Set the value to auto to enable CPU Burst for the pod. \\n  koordinator.sh/cpuBurst: \'{\\"policy\\": \\"auto\\"}\'\\n  # To disable CPU Burst for the pod, set the value to none. \\n  #koordinator.sh/cpuBurst: \'{\\"policy\\": \\"none\\"}\'\\n```\\n\\n- Use a ConfigMap to enable CPU Burst for all pods in a cluster\\n\\n  Modify the slo-controller-config ConfigMap based on the\\n  following content to enable CPU Burst for all pods in a cluster:\\n\\n```yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: slo-controller-config\\n  namespace: koordinator-system\\ndata:\\n  cpu-burst-config: \'{\\"clusterStrategy\\": {\\"policy\\": \\"auto\\"}}\'\\n  #cpu-burst-config: \'{\\"clusterStrategy\\": {\\"policy\\": \\"cpuBurstOnly\\"}}\'\\n  #cpu-burst-config: \'{\\"clusterStrategy\\": {\\"policy\\": \\"none\\"}}\'\\n```\\n\\n- Advanced configurations\\n\\n  The following code block shows the pod annotations and ConfigMap fields that you can use for advanced configurations:\\n\\n```yaml\\n# Example of the slo-controller-config ConfigMap. \\ndata:\\n  cpu-burst-config: |\\n    {\\n      \\"clusterStrategy\\": {\\n        \\"policy\\": \\"auto\\",\\n        \\"cpuBurstPercent\\": 1000,\\n        \\"cfsQuotaBurstPercent\\": 300,\\n        \\"sharePoolThresholdPercent\\": 50,\\n        \\"cfsQuotaBurstPeriodSeconds\\": -1\\n      }\\n    }\\n\\n  # Example of pod annotations. \\n  koordinator.sh/cpuBurst: \'{\\"policy\\": \\"auto\\", \\"cpuBurstPercent\\": 1000, \\"cfsQuotaBurstPercent\\": 300, \\"cfsQuotaBurstPeriodSeconds\\": -1}\'\\n```\\n\\nThe following table describes the ConfigMap fields that you can use for advanced configurations of CPU Burst.\\n\\n| Field                      | Data type | Description                                                                                                                                                                                                                                                                                                                                                                                                                             |\\n|----------------------------|-----------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\\n| policy                     | string    | <ul> <li> none: disables CPU Burst. If you set the value to none, the related fields are reset to their original values. This is the default value.</li> <li>cpuBurstOnly: enables the CPU Burst feature only for the kernel of Alibaba Cloud Linux 2. </li><li> cfsQuotaBurstOnly: enables automatic adjustment of CFS quotas of general kernel versions. </li> <li> auto: enables CPU Burst and all the related features. </li> </ul> |\\n| cpuBurstPercent            | int       | Default value:`1000`. Unit: %. This field specifies the percentage to which the CPU limit can be increased by CPU Burst. If the CPU limit is set to `1`, CPU Burst can increase the limit to 10 by default.                                                                                                                                                                                                                             |\\n| cfsQuotaBurstPercent       | int       | Default value: `300`. Unit: %. This field specifies the maximum percentage to which the value of cfs_quota in the cgroup parameters can be increased. By default, the value of cfs_quota can be increased to at most three times.                                                                                                                                                                                                       |\\n| cfsQuotaBurstPeriodSeconds | int       | Default value: `-1`. Unit: seconds. This indicates that the time period in which the container can run with an increased CFS quota is unlimited. This field specifies the time period in which the container can run with an increased CFS quota, which cannot exceed the upper limit specified by `cfsQuotaBurstPercent`.                                                                                                              |\\n| sharePoolThresholdPercent  | int       | Default value: `50`. Unit: %. This field specifies the CPU utilization threshold of the node. If the CPU utilization of the node exceeds the threshold, the value of cfs_quota in cgroup parameters is reset to the original value.                                                                                                                                                                                                     |\\n\\n## L3 cache and MBA resource isolation\\n\\nPods of different priorities are usually deployed on the same machine. This may cause pods to compete for computing\\nresources. As a result, the quality of service (QoS) of your service cannot be ensured. The Resource Director\\nTechnology (RDT) controls the Last Level Cache (L3 cache) that can be used by workloads of different priorities. RDT\\nalso uses the Memory Bandwidth Allocation (MBA) feature to control the memory bandwidth that can be used by workloads.\\nThis isolates the L3 cache and memory bandwidth used by workloads, ensures the QoS of high-priority workloads, and\\nimproves overall resource utilization. This topic describes how to improve the resource isolation of pods with\\ndifferent priorities by controlling the L3 cache and using the MBA feature.\\n\\n### How to use L3 cache and MBA resource isolation\\n\\n- Use a ConfigMap to enable L3 cache and MBA resource isolation for all pods in a cluster\\n\\n```yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: slo-controller-config\\n  namespace: koordinator-system\\ndata:\\n  resource-qos-config: |-\\n    {\\n      \\"clusterStrategy\\": {\\n        \\"lsClass\\": {\\n           \\"resctrlQoS\\": {\\n             \\"enable\\": true,\\n             \\"catRangeStartPercent\\": 0,\\n             \\"catRangeEndPercent\\": 100,\\n             \\"MBAPercent\\": 100\\n           }\\n         },\\n        \\"beClass\\": {\\n           \\"resctrlQoS\\": {\\n             \\"enable\\": true\\n             \\"catRangeStartPercent\\": 0,\\n             \\"catRangeEndPercent\\": 30,\\n             \\"MBAPercent\\": 100\\n           }\\n         }\\n      }\\n    }\\n```\\n\\n## Memory QoS\\n\\nThe Koordlet provides the memory quality of service (QoS) feature for containers. You can use this\\nfeature to optimize the performance of memory-sensitive applications while ensuring fair memory scheduling among\\ncontainers. This topic describes how to enable the memory QoS feature for containers.\\n\\n### Background information\\n\\nThe following memory limits apply to containers:\\n\\n- The memory limit of the container. If the amount of memory that a container uses, including the page cache, is about\\n  to reach the memory limit of the container, the memory reclaim mechanism of the OS kernel is triggered. As a result,\\n  the application in the container may not be able to request or release memory resources as normal.\\n- The memory limit of the node. If the memory limit of a container is greater than the memory request of the container,\\n  the container can overcommit memory resources. In this case, the available memory on the node may become insufficient.\\n  This causes the OS kernel to reclaim memory from containers. As a result, the performance of your application is\\n  downgraded. In extreme cases, the node cannot run as normal.\\n\\nTo improve the performance of applications and the stability of nodes, Koordinator provides the memory QoS feature for\\ncontainers. We recommend that you use Anolis OS as the node OS. For other OS, we will try our best to adapt, and users\\ncan still enable it without side effects. After you enable the memory QoS feature for a container, Koordlet\\nautomatically configures the memory control group (memcg) based on the configuration of the container. This helps you\\noptimize the performance of memory-sensitive applications while ensuring fair memory scheduling on the node.\\n\\n### How to use Memory QoS\\n\\nWhen you enable memory QoS for the containers in a pod, the memcg is automatically configured based on the specified\\nratios and pod parameters. To enable memory QoS for the containers in a pod, perform the following steps:\\n\\n1. Add the following annotations to enable memory QoS for the containers in a pod:\\n\\n```yaml\\nannotations:\\n  # To enable memory QoS for the containers in a pod, set the value to auto. \\n  koordinator.sh/memoryQoS: \'{\\"policy\\": \\"auto\\"}\'\\n  # To disable memory QoS for the containers in a pod, set the value to none. \\n  #koordinator.sh/memoryQoS: \'{\\"policy\\": \\"none\\"}\'\\n```\\n\\n2. Use a ConfigMap to enable memory QoS for all the containers in a cluster.\\n\\n```yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: slo-controller-config\\n  namespace: koordinator-system\\ndata:\\n  resource-qos-config: |-\\n    {\\n      \\"clusterStrategy\\": {\\n        \\"lsClass\\": {\\n           \\"memoryQoS\\": {\\n             \\"enable\\": true\\n           }\\n         },\\n        \\"beClass\\": {\\n           \\"memoryQoS\\": {\\n             \\"enable\\": true\\n           }\\n         }\\n      }\\n    }\\n```\\n\\n3. Optional. Configure advanced parameters.\\n\\n   The following table describes the advanced parameters that you can use to configure fine-grained memory QoS\\n   configurations at the pod level and cluster level.\\n\\n| Parameter         | Data type | Valid value                                                   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\\n|-------------------|-----------|---------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\\n| enable            | Boolean   | <ul> <li> true </li> <li> false </li> </ul>                   | <ul> <li> true: enables memory QoS for all the containers in a cluster. The default memory QoS settings for the QoS class of the containers are used. </li> <li> false: disables memory QoS for all the containers in a cluster. The memory QoS settings are restored to the original settings for the QoS class of the containers. </li> </ul>                                                                                                                                                                                                                                                                                                                                                             |\\n| policy            | String    | <ul> <li> auto </li> <li> default </li> <li> none </li> </ul> | <ul> <li> auto: enables memory QoS for the containers in the pod and uses the recommended memory QoS settings. The recommended memory QoS settings are prioritized over the cluster-wide memory QoS settings. </li> <li> default: specifies that the pod inherits the cluster-wide memory QoS settings. </li> <li> none: disables memory QoS for the pod. The relevant memory QoS settings are restored to the original settings. The original settings are prioritized over the cluster-wide memory QoS settings. </li> </ul>                                                                                                                                                                              |\\n| minLimitPercent   | Int       | 0~100                                                         | Unit: %. Default value: `0`. The default value indicates that this parameter is disabled. This parameter specifies the unreclaimable proportion of the memory request of a pod. This parameter is suitable for scenarios where applications are sensitive to the page cache. You can use this parameter to cache files to optimize read and write performance. For example, if you specify `Memory Request=100MiB` for a container, the default setting is `memory.min=104857600`.                                                                                                                                                                                                                          |\\n| lowLimitPercent   | Int       | 0~100                                                         | Unit: %. Default value: `0`. The default value indicates that this parameter is disabled. This parameter specifies the relatively unreclaimable proportion of the memory request of a pod. For example, if you specify `Memory Request=100MiB` for a container, the default setting is `memory.low=104857600`.                                                                                                                                                                                                                                                                                                                                                                                              |\\n| throttlingPercent | Int       | 0~100                                                         | Unit: %. Default value: `0`. The default value indicates that this parameter is disabled. This parameter specifies the memory throttling threshold for the ratio of the memory usage of a container to the memory limit of the container. If the usage of the memory limit of a container exceeds the threshold, the memory used by the container will be reclaimed. This parameter is suitable for container memory overcommitment scenarios. You can use this parameter to avoid OOM killers that are triggered by cgroups. For example, if you specify `Memory Request=100MiB` for a container, the default setting is `memory.high=83886080`.                                                           |\\n| wmarkRatio        | Int       | 0~100                                                         | Unit: %. Default value: `95`. A value of `0` indicates that this parameter is disabled. This parameter specifies the threshold of the usage of the memory limit or the value of `memory.high` that triggers asynchronous memory reclaim. If the usage of the memory limit or the value of memory.high exceeds the threshold, the memcg backend asynchronous reclaim feature is triggered. For example, if you specify `Memory Request=100MiB` for a container, the memory throttling setting is `memory.high=83886080`, the reclaim ratio setting is `memory.wmark_ratio=95`, and the reclaim threshold setting is `memory.wmark_high=79691776`.                                                            |\\n| wmarkMinAdj       | Int       | -25~50                                                        | Unit: %. The default value is `-25` for the `LS` QoS class and `50` for the `BE` QoS class. A value of 0 indicates that this parameter is disabled. This parameter specifies the adjustment to the global minimum watermark for a container. A negative value decreases the global minimum watermark and therefore postpones memory reclaim for the container. A positive value increases the global minimum watermark and therefore antedates memory reclaim for the container. For example, if you create a pod whose QoS class is LS, the default setting of this parameter is `memory.wmark_min_adj=-25`, which indicates that the minimum watermark is decreased by 25% for the containers in the pod. |\\n\\n## What Comes Next\\n\\nFor more details, please refer to our [milestone](https://github.com/koordinator-sh/koordinator/milestones). Hope it\\nhelps!"},{"id":"release-v0.2.0","metadata":{"permalink":"/blog/release-v0.2.0","editUrl":"https://github.com/koordinator-sh/koordinator.sh/edit/main/blog/2022-04-19-release/index.md","source":"@site/blog/2022-04-19-release/index.md","title":"Koordinator v0.2.0 - Enhanced node-side scheduling capabilities","description":"We\u2019re pleased to announce the release of Koordinator v0.2.0.","date":"2022-04-19T00:00:00.000Z","formattedDate":"April 19, 2022","tags":[{"label":"koordinator","permalink":"/blog/tags/koordinator"},{"label":"colocation","permalink":"/blog/tags/colocation"},{"label":"kubernetes","permalink":"/blog/tags/kubernetes"},{"label":"scheduling","permalink":"/blog/tags/scheduling"},{"label":"orchestration","permalink":"/blog/tags/orchestration"},{"label":"release","permalink":"/blog/tags/release"}],"readingTime":3.49,"truncated":false,"authors":[{"name":"Joseph","title":"Koordinator maintainer","url":"https://github.com/eahydra","imageURL":"https://github.com/eahydra.png","key":"joseph"}],"frontMatter":{"slug":"release-v0.2.0","title":"Koordinator v0.2.0 - Enhanced node-side scheduling capabilities","authors":["joseph"],"tags":["koordinator","colocation","kubernetes","scheduling","orchestration","release"]},"prevItem":{"title":"What\'s New in Koordinator v0.3.0?","permalink":"/blog/release-v0.3.0"},"nextItem":{"title":"Koordinator v0.1.0 - QoS based scheduling system","permalink":"/blog/release-v0.1.0"}},"content":"We\u2019re pleased to announce the release of Koordinator v0.2.0.\\n\\n## Overview\\n\\nKoordinator v0.1.0 implements basic co-location scheduling capabilities, and after the project was released, it has received attention and positive responses from the community.\\nFor some issues that everyone cares about, such as how to isolate resources for best-effort workloads, how to ensure the runtime stability of latency-sensitiv applications in co-location scenarios, etc., we have enhanced node-side scheduling capabilities in koordinator v0.2.0 to solve these problems.\\n\\n## Install or Upgrade to Koordinator v0.2.0\\n\\n### Install with helms\\n\\nKoordinator can be simply installed by helm v3.5+, which is a simple command-line tool and you can get it from [here](https://github.com/helm/helm/releases).\\n\\n```shell\\n# Firstly add koordinator charts repository if you haven\'t do this.\\n$ helm repo add koordinator-sh https://koordinator-sh.github.io/charts/\\n\\n# [Optional]\\n$ helm repo update\\n\\n# Install the latest version.\\n$ helm install koordinator koordinator-sh/koordinator --version 0.2.0\\n```\\n\\n### Upgrade with helm\\n\\n```shell\\n# Firstly add koordinator charts repository if you haven\'t do this.\\n$ helm repo add koordinator-sh https://koordinator-sh.github.io/charts/\\n\\n# [Optional]\\n$ helm repo update\\n\\n# Upgrade the latest version.\\n$ helm upgrade koordinator koordinator-sh/koordinator --version 0.2.0 [--force]\\n```\\n\\nFor more details, please refer to the [installation manual](/docs/installation).\\n\\n## Isolate resources for best-effort workloads\\n\\nIn Koodinator v0.2.0, we refined the ability to isolate resources for best-effort worklods. \\n\\n`koordlet` will set the cgroup parameters according to the resources described in the Pod Spec. Currently supports setting CPU Request/Limit, and Memory Limit.\\n\\nFor CPU resources, only the case of `request == limit` is supported, and the support for the scenario of `request <= limit` will be supported in the next version.\\n\\n## Active eviction mechanism based on memory safety thresholds\\n\\nWhen latency-sensitiv applications are serving, memory usage may increase due to bursty traffic. Similarly, there may be similar scenarios for best-effort workloads, for example, the current computing load exceeds the expected resource Request/Limit. \\n\\nThese scenarios will lead to an increase in the overall memory usage of the node, which will have an unpredictable impact on the runtime stability of the node side. For example, it can reduce the quality of service of latency-sensitiv applications or even become unavailable. Especially in a co-location environment, it is more challenging.\\n\\nWe implemented an active eviction mechanism based on memory safety thresholds in Koodinator. \\n\\n`koordlet` will regularly check the recent memory usage of node and Pods to check whether the safty threshold is exceeded. If it exceeds, it will evict some best-effort Pods to release memory. This mechanism can better ensure the stability of node and latency-sensitiv applications.\\n\\n`koordlet` currently only evicts best-effort Pods, sorted according to the Priority specified in the Pod Spec. The lower the priority, the higher the priority to be evicted, the same priority will be sorted according to the memory usage rate (RSS), the higher the memory usage, the higher the priority to be evicted. This eviction selection algorithm is not static. More dimensions will be considered in the future, and more refined implementations will be implemented for more scenarios to achieve more reasonable evictions.\\n\\nThe current memory utilization safety threshold default value is 70%. You can modify the `memoryEvictThresholdPercent` in ConfigMap `slo-controller-config` according to the actual situation, \\n\\n```yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: slo-controller-config\\n  namespace: koordinator-system\\ndata:\\n  colocation-config: |\\n    {\\n      \\"enable\\": true\\n    }\\n  resource-threshold-config: |\\n    {\\n      \\"clusterStrategy\\": {\\n        \\"enable\\": true,\\n        \\"memoryEvictThresholdPercent\\": 70\\n      }\\n    }\\n```\\n\\n## CPU Burst - Improve the performance of latency-sensitive applications\\n\\nCPU Burst is a service level objective (SLO)-aware resource scheduling feature. You can use CPU Burst to improve the performance of latency-sensitive applications. CPU scheduling for a container may be throttled by the kernel due to the CPU limit, which downgrades the performance of the application. Koordinator automatically detects CPU throttling events and automatically adjusts the CPU limit to a proper value. This greatly improves the performance of latency-sensitive applications. \\n\\nThe code of CPU Burst has been developed and is still under review and testing. It will be released in the next version. If you want to use this ability early, you are welcome to participate in Koordiantor and improve it together. For more details, please refer to the PR [#73](https://github.com/koordinator-sh/koordinator/pull/73).\\n\\n## More\\n\\nFor more details, please refer to the [Documentation](/docs). Hope it helps!"},{"id":"release-v0.1.0","metadata":{"permalink":"/blog/release-v0.1.0","editUrl":"https://github.com/koordinator-sh/koordinator.sh/edit/main/blog/2022-03-31-release/index.md","source":"@site/blog/2022-03-31-release/index.md","title":"Koordinator v0.1.0 - QoS based scheduling system","description":"We\u2019re pleased to announce the release of Koordinator v0.1.0.","date":"2022-03-31T00:00:00.000Z","formattedDate":"March 31, 2022","tags":[{"label":"koordinator","permalink":"/blog/tags/koordinator"},{"label":"colocation","permalink":"/blog/tags/colocation"},{"label":"kubernetes","permalink":"/blog/tags/kubernetes"},{"label":"scheduling","permalink":"/blog/tags/scheduling"},{"label":"orchestration","permalink":"/blog/tags/orchestration"},{"label":"release","permalink":"/blog/tags/release"}],"readingTime":4.21,"truncated":false,"authors":[{"name":"Joseph","title":"Koordinator maintainer","url":"https://github.com/eahydra","imageURL":"https://github.com/eahydra.png","key":"joseph"},{"name":"Fangsong Zeng","title":"Koordinator maintainer","url":"https://github.com/hormes","imageURL":"https://github.com/hormes.png","key":"hormes"}],"frontMatter":{"slug":"release-v0.1.0","title":"Koordinator v0.1.0 - QoS based scheduling system","authors":["joseph","hormes"],"tags":["koordinator","colocation","kubernetes","scheduling","orchestration","release"]},"prevItem":{"title":"Koordinator v0.2.0 - Enhanced node-side scheduling capabilities","permalink":"/blog/release-v0.2.0"}},"content":"We\u2019re pleased to announce the release of Koordinator v0.1.0.\\n\\n## Overview\\nKoordinator is a QoS based scheduling system for hybrid workloads orchestration on Kubernetes. It aims to improve the runtime efficiency and reliability of both latency sensitive workloads and batch jobs, simplify the complexity of resource-related configuration tuning, and increase pod deployment density to improve resource utilizations.\\n\\n## Key Features\\nKoordinator enhances the kubernetes user experiences in the workload management by providing the following:\\n\\n- Well-designed [priority](/docs/key-designs/priority) and [QoS](/docs/key-designs/qos) mechanism to co-locate different types of workloads in a cluster and run different types of pods on a single node.\\nAllowing for resource overcommitments to achieve high resource utilizations but still satisfying the QoS guarantees by leveraging an application profiling mechanism.\\n- Fine-grained resource orchestration and isolation mechanism to improve the efficiency of latency-sensitive workloads and batch jobs.\\n- Flexible job scheduling mechanism to support workloads in specific areas, e.g., big data, AI, audio and video.\\n- A set of tools for monitoring, troubleshooting and operations.\\n\\n## Node Metrics \\n\\nKoordinator defines the `NodeMetrics` CRD, which is used to record the resource utilization of a single node and all Pods on the node. koordlet will regularly report and update `NodeMetrics`. You can view `NodeMetrics` with the following commands.\\n\\n```shell\\n$ kubectl get nodemetrics node-1 -o yaml\\napiVersion: slo.koordinator.sh/v1alpha1\\nkind: NodeMetric\\nmetadata:\\n  creationTimestamp: \\"2022-03-30T11:50:17Z\\"\\n  generation: 1\\n  name: node-1\\n  resourceVersion: \\"2687986\\"\\n  uid: 1567bb4b-87a7-4273-a8fd-f44125c62b80\\nspec: {}\\nstatus:\\n  nodeMetric:\\n    nodeUsage:\\n      resources:\\n        cpu: 138m\\n        memory: \\"1815637738\\"\\n  podsMetric:\\n  - name: storage-service-6c7c59f868-k72r5\\n    namespace: default\\n    podUsage:\\n      resources:\\n        cpu: \\"300m\\"\\n        memory: 17828Ki\\n```\\n\\n## Colocation Resources\\n\\nAfter the Koordinator is deployed in the K8s cluster, the Koordinator will calculate the CPU and Memory resources that have been allocated but not used according to the data of `NodeMetrics`. These resources are updated in Node in the form of extended resources. \\n\\n`koordinator.sh/batch-cpu` represents the CPU resources for Best Effort workloads, \\n`koordinator.sh/batch-memory` represents the Memory resources for Best Effort workloads. \\n\\nYou can view these resources with the following commands.\\n\\n```shell\\n$ kubectl describe node node-1\\nName:               node-1\\n....\\nCapacity:\\n  cpu:                          8\\n  ephemeral-storage:            103080204Ki\\n  koordinator.sh/batch-cpu:     4541\\n  koordinator.sh/batch-memory:  17236565027\\n  memory:                       32611012Ki\\n  pods:                         64\\nAllocatable:\\n  cpu:                          7800m\\n  ephemeral-storage:            94998715850\\n  koordinator.sh/batch-cpu:     4541\\n  koordinator.sh/batch-memory:  17236565027\\n  memory:                       28629700Ki\\n  pods:                         64\\n```\\n\\n\\n## Cluster-level Colocation Profile\\n\\nIn order to make it easier for everyone to use Koordinator to co-locate different workloads, we defined `ClusterColocationProfile` to help gray workloads use co-location resources. A `ClusterColocationProfile` is CRD like the one below. Please do edit each parameter to fit your own use cases.\\n\\n```yaml\\napiVersion: config.koordinator.sh/v1alpha1\\nkind: ClusterColocationProfile\\nmetadata:\\n  name: colocation-profile-example\\nspec:\\n  namespaceSelector:\\n    matchLabels:\\n      koordinator.sh/enable-colocation: \\"true\\"\\n  selector:\\n    matchLabels:\\n      sparkoperator.k8s.io/launched-by-spark-operator: \\"true\\"\\n  qosClass: BE\\n  priorityClassName: koord-batch\\n  koordinatorPriority: 1000\\n  schedulerName: koord-scheduler\\n  labels:\\n    koordinator.sh/mutated: \\"true\\"\\n  annotations: \\n    koordinator.sh/intercepted: \\"true\\"\\n  patch:\\n    spec:\\n      terminationGracePeriodSeconds: 30\\n```\\n\\nVarious Koordinator components ensure scheduling and runtime quality through labels `koordinator.sh/qosClass`, `koordinator.sh/priority` and kubernetes native priority.\\n\\nWith the webhook mutating mechanism provided by Kubernetes, koord-manager will modify Pod resource requirements to co-located resources, and inject the QoS and Priority defined by Koordinator into Pod.\\n\\nTaking the above Profile as an example, when the Spark Operator creates a new Pod in the namespace with the `koordinator.sh/enable-colocation=true` label, the Koordinator QoS label `koordinator.sh/qosClass` will be injected into the Pod. According to the Profile definition PriorityClassName, modify the Pod\'s PriorityClassName and the corresponding Priority value. Users can also set the Koordinator Priority according to their needs to achieve more fine-grained priority management, so the Koordinator Priority label `koordinator.sh/priority` is also injected into the Pod. Koordinator provides an enhanced scheduler koord-scheduler, so you need to modify the Pod\'s scheduler name koord-scheduler through Profile.\\n\\nIf you expect to integrate Koordinator into your own system, please learn more about the [core concepts](/docs/key-designs/overview).\\n\\n## CPU Suppress\\n\\nIn order to ensure the runtime quality of different workloads in co-located scenarios, Koordinator uses the CPU Suppress mechanism provided by koordlet on the node side to suppress workloads of the Best Effort type when the load increases. Or increase the resource quota for Best Effort type workloads when the load decreases.\\n\\nWhen installing through the helm chart, the ConfigMap `slo-controller-config` will be created in the koordinator-system namespace, and the CPU Suppress mechanism is enabled by default. If it needs to be closed, refer to the configuration below, and modify the configuration of the resource-threshold-config section to take effect.\\n\\n```yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: slo-controller-config\\n  namespace: {{ .Values.installation.namespace }}\\ndata:\\n  ...\\n  resource-threshold-config: |\\n    {\\n      \\"clusterStrategy\\": {\\n        \\"enable\\": false\\n      }\\n    }\\n```\\n\\n## Colocation Resources Balance\\nKoordinator currently adopts a strategy for node co-location resource scheduling, which prioritizes scheduling to machines with more resources remaining in co-location to avoid Best Effort workloads crowding together. More rich scheduling capabilities are on the way.\\n\\n## Tutorial - Colocation of Spark Jobs\\n\\nApache Spark is an analysis engine for large-scale data processing, which is widely used in Big Data, SQL Analysis and Machine Learning scenarios. \\nWe provide a tutorial to help you how to quickly use Koordinator to run Spark Jobs in colocation mode with other latency sensitive applications. For more details, please refer to the [tutorial](/docs/best-practices/colocation-of-spark-jobs).\\n\\n## Summary\\n\\nFore More details, please refer to the [Documentation](/docs). Hope it helps!"}]}')}}]);