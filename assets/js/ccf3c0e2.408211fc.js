"use strict";(self.webpackChunkkoordinator_sh=self.webpackChunkkoordinator_sh||[]).push([[4266],{3905:function(e,n,t){t.d(n,{Zo:function(){return c},kt:function(){return h}});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=a.createContext({}),d=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},c=function(e){var n=d(e.components);return a.createElement(s.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},p=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),p=d(t),h=r,m=p["".concat(s,".").concat(h)]||p[h]||u[h]||o;return t?a.createElement(m,i(i({ref:n},c),{},{components:t})):a.createElement(m,i({ref:n},c))}));function h(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,i=new Array(o);i[0]=p;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var d=2;d<o;d++)i[d]=t[d];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}p.displayName="MDXCreateElement"},8009:function(e,n,t){t.r(n),t.d(n,{assets:function(){return c},contentTitle:function(){return s},default:function(){return h},frontMatter:function(){return l},metadata:function(){return d},toc:function(){return u}});var a=t(7462),r=t(3366),o=(t(7294),t(3905)),i=["components"],l={},s="Load Aware Scheduling",d={unversionedId:"user-manuals/load-aware-scheduling",id:"version-v0.5/user-manuals/load-aware-scheduling",title:"Load Aware Scheduling",description:"Load Aware Scheduling is an ability of koord-scheduler for balancing pods scheduling based on the real-time load of each node.",source:"@site/versioned_docs/version-v0.5/user-manuals/load-aware-scheduling.md",sourceDirName:"user-manuals",slug:"/user-manuals/load-aware-scheduling",permalink:"/docs/user-manuals/load-aware-scheduling",editUrl:"https://github.com/koordinator-sh/koordinator.sh/edit/main/docs/user-manuals/load-aware-scheduling.md",tags:[],version:"v0.5",lastUpdatedBy:"Jason Liu",lastUpdatedAt:1656909557,formattedLastUpdatedAt:"7/4/2022",frontMatter:{},sidebar:"docs",previous:{title:"Colocation Profile",permalink:"/docs/user-manuals/colocation-profile"},next:{title:"Fine-grained CPU Orchestration",permalink:"/docs/user-manuals/fine-grained-cpu-orchestration"}},c={},u=[{value:"Introduction",id:"introduction",level:2},{value:"Setup",id:"setup",level:2},{value:"Prerequisite",id:"prerequisite",level:3},{value:"Installation",id:"installation",level:3},{value:"Configurations",id:"configurations",level:3},{value:"(Optional) Advanced Settings",id:"optional-advanced-settings",level:4},{value:"Use Load Aware Scheduling",id:"use-load-aware-scheduling",level:2}],p={toc:u};function h(e){var n=e.components,l=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,a.Z)({},p,l,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"load-aware-scheduling"},"Load Aware Scheduling"),(0,o.kt)("p",null,"Load Aware Scheduling is an ability of koord-scheduler for balancing pods scheduling based on the real-time load of each node."),(0,o.kt)("h2",{id:"introduction"},"Introduction"),(0,o.kt)("p",null,"Load balancing is a common issue in resource scheduling. Under-utilized nodes bring much resource waste to the\ncluster, while over-utilized nodes are likely to cause performance degradation. Neither of them is suitable for\nefficient resource management."),(0,o.kt)("p",null,"The native Kubernetes scheduler schedules pods based on the requests and the allocation of nodes, considering neither\nthe real-time load nor the estimated usage. When we want to balance the pod scheduling on each node and make the loads\neven with the native scheduler, we need to set precise resource requirements for the applications. Moreover, since\nKoordinator enables resource overcommitment to achieve better resource efficiency, we need a mechanism to reduce the\nprobability of performance degradation and avoid over-utilization."),(0,o.kt)("p",null,"Koord-scheduler can retrieve node metrics by cooperating with the koordlet. It provides the ability to balance the\nscheduling of both the online (LSE/LSR/LS) pods and offline (BE) pods based on node utilization."),(0,o.kt)("p",null,(0,o.kt)("img",{loading:"lazy",alt:"image",src:t(2503).Z,width:"611",height:"466"})),(0,o.kt)("p",null,"For more information, please see ",(0,o.kt)("a",{parentName:"p",href:"/docs/designs/load-aware-scheduling"},"Design: Load Aware Scheduling"),"."),(0,o.kt)("h2",{id:"setup"},"Setup"),(0,o.kt)("h3",{id:"prerequisite"},"Prerequisite"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Kubernetes >= 1.18"),(0,o.kt)("li",{parentName:"ul"},"Koordinator >= 0.4")),(0,o.kt)("h3",{id:"installation"},"Installation"),(0,o.kt)("p",null,"Please make sure Koordinator components are correctly installed in your cluster. If not, please refer to ",(0,o.kt)("a",{parentName:"p",href:"/docs/installation"},"Installation"),"."),(0,o.kt)("h3",{id:"configurations"},"Configurations"),(0,o.kt)("p",null,"Load-aware scheduling is ",(0,o.kt)("em",{parentName:"p"},"Enabled")," by default. You can use it without any modification on the koord-scheduler config."),(0,o.kt)("h4",{id:"optional-advanced-settings"},"(Optional) Advanced Settings"),(0,o.kt)("p",null,"For users who need deep insight, please configure the rules of load-aware scheduling by modifying the ConfigMap\n",(0,o.kt)("inlineCode",{parentName:"p"},"koord-scheduler-config")," in the helm chart."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: koord-scheduler-config\n  ...\ndata:\n  koord-scheduler-config: |\n    apiVersion: kubescheduler.config.k8s.io/v1beta2\n    kind: KubeSchedulerConfiguration\n    profiles:\n      - schedulerName: koord-scheduler\n        plugins:\n          # enable the LoadAwareScheduling plugin\n          filter:\n            enabled:\n              - name: LoadAwareScheduling\n              ...\n          score:\n            enabled:\n              - name: LoadAwareScheduling\n                weight: 1\n              ...\n          reserve:\n            enabled:\n              - name: LoadAwareScheduling\n          ...\n        pluginConfig:\n        # configure the thresholds and weights for the plugin\n        - name: LoadAwareScheduling\n          args:\n            apiVersion: kubescheduler.config.k8s.io/v1beta2\n            kind: LoadAwareSchedulingArgs\n            # whether to filter nodes where koordlet fails to update NodeMetric\n            filterExpiredNodeMetrics: true\n            # the expiration threshold seconds when using NodeMetric\n            nodeMetricExpirationSeconds: 300\n            # weights of resources\n            resourceWeights:\n              cpu: 1\n              memory: 1\n            # thresholds (%) of resource utilization\n            usageThresholds:\n              cpu: 75\n              memory: 85\n            # the factor (%) for estimating resource usage\n            estimatedScalingFactors:\n              cpu: 80\n              memory: 70\n")),(0,o.kt)("p",null,"The koord-scheduler takes this ConfigMap as ",(0,o.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/reference/scheduling/config/"},"scheduler Configuration"),".\nNew configurations will take effect after the koord-scheduler restarts."),(0,o.kt)("h2",{id:"use-load-aware-scheduling"},"Use Load Aware Scheduling"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Deploy a ",(0,o.kt)("inlineCode",{parentName:"li"},"stress")," pod with the YAML file below.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Pod\nmetadata:\n  name: stress-demo\n  labels:\n    name: stress-demo\nspec:\n  containers:\n    - args:\n        - '--vm'\n        - '2'\n        - '--vm-bytes'\n        - '2G'\n        - '-c'\n        - '2'\n        - '--vm-hang'\n        - '2'\n      command:\n        - stress\n      image: polinux/stress\n      imagePullPolicy: Always\n      name: stress\n      resources:\n        limits:\n          cpu: '2'\n          memory: 4Gi\n        requests:\n          cpu: 200m\n          memory: 1Gi\n  restartPolicy: Always\n  schedulerName: koord-scheduler # use the koord-scheduler\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl create -f stress-demo.yaml\npod/stress-demo created\n")),(0,o.kt)("ol",{start:2},(0,o.kt)("li",{parentName:"ol"},"Watch the pod status util it becomes running.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl get pod stress-demo -w\nNAME          READY   STATUS    RESTARTS   AGE    IP             NODE     NOMINATED NODE   READINESS GATES\nstress-demo   1/1     Running   0          20s    172.20.100.6   node-0   <none>           <none>\n")),(0,o.kt)("p",null,"The pod is scheduled on ",(0,o.kt)("inlineCode",{parentName:"p"},"node-0"),"."),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},"Check the load of each node.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl top node\nNAME     CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%\nnode-0   6450m        19%    25091Mi         19%\nnode-2   3280m        10%    17535Mi         13%\nnode-1   2687m        8%     9631Mi          7%\n")),(0,o.kt)("p",null,"In above order, ",(0,o.kt)("inlineCode",{parentName:"p"},"node-0")," has the highest load, while ",(0,o.kt)("inlineCode",{parentName:"p"},"node-1")," has the lowest load."),(0,o.kt)("ol",{start:4},(0,o.kt)("li",{parentName:"ol"},"Deploy an ",(0,o.kt)("inlineCode",{parentName:"li"},"nginx")," deployment with the YAML file below.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      name: nginx\n      labels:\n        app: nginx\n    spec:\n      schedulerName: koord-scheduler # use the koord-scheduler\n      containers:\n      - name: nginx\n        image: nginx\n        resources:\n          limits:\n            cpu: 500m\n          requests:\n            cpu: 500m\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl create -f nginx-deployment.yaml\ndeployment/nginx created\n")),(0,o.kt)("ol",{start:5},(0,o.kt)("li",{parentName:"ol"},"Check the scheduling results of ",(0,o.kt)("inlineCode",{parentName:"li"},"nginx")," pods.")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"$ kubectl get pods | grep nginx\nnginx-7585b886cb-5b6vq   1/1     Running   0       32s     172.20.101.6    node-1   <none>         <none>\nnginx-7585b886cb-4mdlh   1/1     Running   0       32s     172.20.106.20   node-2   <none>         <none>\n")),(0,o.kt)("p",null,"Now we can see ",(0,o.kt)("inlineCode",{parentName:"p"},"nginx")," pods get scheduled on the nodes other than ",(0,o.kt)("inlineCode",{parentName:"p"},"node-0")," (node with the highest load)."))}h.isMDXComponent=!0},2503:function(e,n,t){n.Z=t.p+"assets/images/load-aware-scheduling-arch-cfa9bc8e584faf58a3c7807fd699361a.svg"}}]);